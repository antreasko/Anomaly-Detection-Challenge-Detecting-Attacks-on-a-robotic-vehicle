{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/andreas/Desktop/Cyberlens/Pre-interview_assessment/vulnerable_robot_challenge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>CPU</th>\n",
       "      <th>RxKBTot</th>\n",
       "      <th>TxKBTot</th>\n",
       "      <th>WriteKBTot</th>\n",
       "      <th>Watts</th>\n",
       "      <th>Amps</th>\n",
       "      <th>RMS</th>\n",
       "      <th>diff_encoder_l</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>4132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>171.991452</td>\n",
       "      <td>23.350803</td>\n",
       "      <td>244.917846</td>\n",
       "      <td>14.778896</td>\n",
       "      <td>0.923035</td>\n",
       "      <td>89.733106</td>\n",
       "      <td>0.566935</td>\n",
       "      <td>0.158382</td>\n",
       "      <td>17.305770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.230427</td>\n",
       "      <td>9.146263</td>\n",
       "      <td>1353.260313</td>\n",
       "      <td>77.508104</td>\n",
       "      <td>1.511957</td>\n",
       "      <td>9.041810</td>\n",
       "      <td>0.059048</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>8.762966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>112.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.700000</td>\n",
       "      <td>0.401004</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>148.580000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.536825</td>\n",
       "      <td>0.106521</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>164.970000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.700000</td>\n",
       "      <td>0.587531</td>\n",
       "      <td>0.148595</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>199.645000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>98.176835</td>\n",
       "      <td>0.614895</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>22.943282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>228.780000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>8801.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>101.199602</td>\n",
       "      <td>0.635988</td>\n",
       "      <td>1.136100</td>\n",
       "      <td>89.718974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t          CPU      RxKBTot      TxKBTot   WriteKBTot  \\\n",
       "count  4132.000000  4132.000000  4132.000000  4132.000000  4132.000000   \n",
       "mean    171.991452    23.350803   244.917846    14.778896     0.923035   \n",
       "std      33.230427     9.146263  1353.260313    77.508104     1.511957   \n",
       "min     112.220000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     148.580000    26.000000     1.000000     0.960000     0.000000   \n",
       "50%     164.970000    26.800000     1.000000     1.000000     0.000000   \n",
       "75%     199.645000    27.000000     1.000000     1.000000     1.520000   \n",
       "max     228.780000    42.000000  8801.000000   506.000000    10.000000   \n",
       "\n",
       "             Watts         Amps          RMS  diff_encoder_l    flag  \n",
       "count  4132.000000  4132.000000  4132.000000     4132.000000  4132.0  \n",
       "mean     89.733106     0.566935     0.158382       17.305770     0.0  \n",
       "std       9.041810     0.059048     0.087423        8.762966     0.0  \n",
       "min      62.700000     0.401004     0.008099        0.000012     0.0  \n",
       "25%      84.000000     0.536825     0.106521       11.200000     0.0  \n",
       "50%      92.700000     0.587531     0.148595       18.000000     0.0  \n",
       "75%      98.176835     0.614895     0.196046       22.943282     0.0  \n",
       "max     101.199602     0.635988     1.136100       89.718974     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = df.loc[df['flag'] == 0, :]\n",
    "normal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>CPU</th>\n",
       "      <th>RxKBTot</th>\n",
       "      <th>TxKBTot</th>\n",
       "      <th>WriteKBTot</th>\n",
       "      <th>Watts</th>\n",
       "      <th>Amps</th>\n",
       "      <th>RMS</th>\n",
       "      <th>diff_encoder_l</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.000000</td>\n",
       "      <td>4804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>173.063281</td>\n",
       "      <td>18.942756</td>\n",
       "      <td>4333.229184</td>\n",
       "      <td>244.369484</td>\n",
       "      <td>1.369172</td>\n",
       "      <td>87.776590</td>\n",
       "      <td>0.566919</td>\n",
       "      <td>0.159151</td>\n",
       "      <td>14.446373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.462097</td>\n",
       "      <td>7.969489</td>\n",
       "      <td>4321.163783</td>\n",
       "      <td>244.466168</td>\n",
       "      <td>1.907361</td>\n",
       "      <td>7.370592</td>\n",
       "      <td>0.058446</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>8.305075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.575296</td>\n",
       "      <td>0.400111</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>157.995000</td>\n",
       "      <td>11.240000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.900000</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.080659</td>\n",
       "      <td>10.396769</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>2892.570000</td>\n",
       "      <td>119.340000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>92.479720</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>192.005000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8695.620000</td>\n",
       "      <td>498.280000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>0.603124</td>\n",
       "      <td>0.187214</td>\n",
       "      <td>20.333341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>8810.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>98.743706</td>\n",
       "      <td>0.631980</td>\n",
       "      <td>1.817189</td>\n",
       "      <td>84.166746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t          CPU      RxKBTot      TxKBTot   WriteKBTot  \\\n",
       "count  4804.000000  4804.000000  4804.000000  4804.000000  4804.000000   \n",
       "mean    173.063281    18.942756  4333.229184   244.369484     1.369172   \n",
       "std      25.462097     7.969489  4321.163783   244.466168     1.907361   \n",
       "min     122.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%     157.995000    11.240000     0.960000     0.000000     0.000000   \n",
       "50%     177.000000    12.870000  2892.570000   119.340000     0.560000   \n",
       "75%     192.005000    27.000000  8695.620000   498.280000     2.160000   \n",
       "max     215.000000    41.000000  8810.000000   508.000000    11.000000   \n",
       "\n",
       "             Watts         Amps          RMS  diff_encoder_l    flag  \n",
       "count  4804.000000  4804.000000  4804.000000     4804.000000  4804.0  \n",
       "mean     87.776590     0.566919     0.159151       14.446373     1.0  \n",
       "std       7.370592     0.058446     0.137175        8.305075     0.0  \n",
       "min      62.575296     0.400111     0.008062        0.000000     1.0  \n",
       "25%      83.900000     0.542000     0.080659       10.396769     1.0  \n",
       "50%      92.479720     0.592000     0.126455       13.000000     1.0  \n",
       "75%      93.200000     0.603124     0.187214       20.333341     1.0  \n",
       "max      98.743706     0.631980     1.817189       84.166746     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = df.loc[df['flag'] == 1, :]\n",
    "fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4132, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4132, 4)\n",
      "(4132,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "columns = [1, 2, 3, 5]\n",
    "\n",
    "Data_norm = MinMaxScaler().fit_transform(df.iloc[:,:-1])\n",
    "Data_norm = pd.DataFrame(Data_norm)\n",
    "Data_norm['flag'] = df['flag']\n",
    "normal = Data_norm.loc[Data_norm['flag'] == 0, :]\n",
    "fraud = Data_norm.loc[Data_norm['flag'] == 1, :]\n",
    "\n",
    "# Data = Data_norm.sample(frac = .2, random_state = 42)\n",
    "X = normal.loc[:,columns]\n",
    "y = normal['flag']\n",
    "X_at = fraud.loc[:,columns]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_this = X_at.iloc[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.549517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         5\n",
       "491  0.642857  0.000114  0.001969  0.549517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_normal_train, x_normal_test = train_test_split(\n",
    "    X, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal train count: 3099\n",
      "Normal test count: 1033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Normal train count: {len(x_normal_train)}\")\n",
    "print(f\"Normal test count: {len(x_normal_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                125       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 104       \n",
      "=================================================================\n",
      "Total params: 407\n",
      "Trainable params: 407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - 0s 954us/step - loss: 0.1012\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 894us/step - loss: 0.0102\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 870us/step - loss: 0.0028\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 835us/step - loss: 8.8280e-04\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 877us/step - loss: 4.0239e-04\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 929us/step - loss: 2.3756e-04\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 853us/step - loss: 1.6442e-04\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 847us/step - loss: 1.3189e-04\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 914us/step - loss: 1.1183e-04\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 888us/step - loss: 9.0290e-05\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 871us/step - loss: 7.6720e-05\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 788us/step - loss: 6.8463e-05\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 946us/step - loss: 6.2658e-05\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 899us/step - loss: 5.5916e-05\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 919us/step - loss: 5.0257e-05\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 849us/step - loss: 4.5117e-05\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 959us/step - loss: 4.0796e-05\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 963us/step - loss: 3.5492e-05\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 858us/step - loss: 3.2449e-05\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 909us/step - loss: 3.0032e-05\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 808us/step - loss: 2.7965e-05\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 958us/step - loss: 2.4852e-05\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 973us/step - loss: 2.2232e-05\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 877us/step - loss: 2.2712e-05\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 887us/step - loss: 1.9283e-05\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 808us/step - loss: 1.7886e-05\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 905us/step - loss: 1.7021e-05\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.5540e-05\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.2980e-05\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 882us/step - loss: 9.4007e-06\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 828us/step - loss: 8.6092e-06\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 7.4922e-06\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 7.4903e-06\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 7.2530e-06\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 821us/step - loss: 6.4504e-06\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 776us/step - loss: 6.2183e-06\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 849us/step - loss: 5.8748e-06\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 978us/step - loss: 5.6871e-06\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 886us/step - loss: 6.5195e-06\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 784us/step - loss: 5.1525e-06\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 850us/step - loss: 5.4921e-06\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 873us/step - loss: 4.8553e-06\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 870us/step - loss: 5.0876e-06\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 913us/step - loss: 4.9687e-06\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 882us/step - loss: 4.5708e-06\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 913us/step - loss: 5.2021e-06\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 965us/step - loss: 4.6011e-06\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 791us/step - loss: 4.6585e-06\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 728us/step - loss: 4.2928e-06\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 726us/step - loss: 4.0456e-06\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 696us/step - loss: 3.6259e-06\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 764us/step - loss: 3.7128e-06\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 632us/step - loss: 3.4104e-06\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 766us/step - loss: 3.0993e-06\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 659us/step - loss: 3.1652e-06\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 752us/step - loss: 3.1998e-06\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 680us/step - loss: 3.3971e-06\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 681us/step - loss: 2.9413e-06\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 812us/step - loss: 3.1389e-06\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 710us/step - loss: 2.8580e-06\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 697us/step - loss: 2.3001e-06\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 674us/step - loss: 2.2496e-06\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 731us/step - loss: 2.2606e-06\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 708us/step - loss: 3.2042e-06\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 0s 685us/step - loss: 2.4164e-06\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 0s 790us/step - loss: 2.4020e-06\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 0s 723us/step - loss: 1.9544e-06\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 0s 720us/step - loss: 1.9806e-06\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 0s 700us/step - loss: 2.0707e-06\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 0s 676us/step - loss: 1.9958e-06\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 0s 690us/step - loss: 1.7214e-06\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 0s 696us/step - loss: 1.5898e-06\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 0s 944us/step - loss: 1.5974e-06\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 0s 857us/step - loss: 1.8283e-06\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 0s 718us/step - loss: 1.4968e-06\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 0s 648us/step - loss: 1.5872e-06\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 0s 727us/step - loss: 9.6948e-07\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 0s 675us/step - loss: 1.3656e-06\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 0s 714us/step - loss: 1.3787e-06\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 0s 796us/step - loss: 2.6318e-06\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 0s 694us/step - loss: 1.3877e-05\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 0s 683us/step - loss: 2.8064e-06\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 0s 691us/step - loss: 6.2930e-07\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 0s 687us/step - loss: 9.1061e-07\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 0s 708us/step - loss: 1.4617e-06\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 0s 684us/step - loss: 7.4073e-07\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 0s 738us/step - loss: 5.0683e-06\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 0s 741us/step - loss: 2.4754e-06\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 0s 697us/step - loss: 6.6766e-07\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 0s 824us/step - loss: 4.4914e-07\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 0s 746us/step - loss: 5.9592e-07\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 0s 681us/step - loss: 1.1398e-06\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 0s 714us/step - loss: 6.6081e-07\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 0s 676us/step - loss: 6.0466e-07\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 0s 720us/step - loss: 8.2375e-07\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 0s 719us/step - loss: 8.4535e-07\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 0s 713us/step - loss: 8.0450e-07\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 0s 745us/step - loss: 7.0711e-07\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 0s 712us/step - loss: 1.1177e-06\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 0s 751us/step - loss: 8.5321e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c0429ce80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(X.shape[1])) # Multiple output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "model.fit(x_normal_train,x_normal_train,verbose=1,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Score (RMSE): 0.0009896291869394512\n",
      "Insample Normal Score (RMSE): 0.000981324502080185\n",
      "Attack Underway Score (RMSE): 0.019791063111534467\n"
     ]
    }
   ],
   "source": [
    "pred1 = model.predict(x_normal_test)\n",
    "score1 = np.sqrt(metrics.mean_squared_error(pred1,x_normal_test))\n",
    "\n",
    "\n",
    "pred2 = model.predict(X)\n",
    "score2 = np.sqrt(metrics.mean_squared_error(pred2,X))\n",
    "\n",
    "\n",
    "pred3 = model.predict(X_at)\n",
    "score3 = np.sqrt(metrics.mean_squared_error(pred3,X_at))\n",
    "\n",
    "\n",
    "print(f\"Out of Sample Score (RMSE): {score1}\")\n",
    "print(f\"Insample Normal Score (RMSE): {score2}\")\n",
    "print(f\"Attack Underway Score (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error threshold:  0.0009896291869394512\n"
     ]
    }
   ],
   "source": [
    "threshold = np.max(score1)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(prediction):\n",
    "    if prediction > threshold:\n",
    "        print(\"anomaly\")\n",
    "    else:\n",
    "        print(\"we are doing good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005611648567257975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test = model.predict(test_this)\n",
    "score_test1 = np.sqrt(metrics.mean_squared_error(score_test,test_this))\n",
    "score_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are doing good\n"
     ]
    }
   ],
   "source": [
    "check_status(score_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266    0.423810\n",
       "2161    0.642857\n",
       "5326    0.214286\n",
       "2703    0.023810\n",
       "2046    0.646190\n",
       "          ...   \n",
       "8706    0.638095\n",
       "6025    0.629048\n",
       "7519    0.655714\n",
       "1651    0.642857\n",
       "2061    0.653333\n",
       "Name: 1, Length: 1033, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_normal_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X[1])\n",
    "# plt.show()\n",
    "# plt.plot(pred2[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00544834])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = score1.reshape((-1))\n",
    "score1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomaly samples:  1\n",
      "Indices of anomaly samples:  (array([0]),)\n"
     ]
    }
   ],
   "source": [
    "anomalies = (score1 > threshold).tolist()\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
